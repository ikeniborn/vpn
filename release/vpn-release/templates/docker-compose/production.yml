# Production Environment Override
# Use with: docker-compose -f base.yml -f production.yml up
version: '3.8'

services:
  vpn-server:
    deploy:
      replicas: 3
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    environment:
      - XRAY_LOG_LEVEL=warning
      - PRODUCTION=true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=64m

  nginx-proxy:
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    volumes:
      - ./configs/nginx/prod:/etc/nginx/conf.d:ro
      - nginx-certs:/etc/nginx/certs:ro
      - ./ssl:/etc/ssl/certs:ro
    environment:
      - NGINX_WORKER_PROCESSES=auto
      - NGINX_WORKER_CONNECTIONS=1024
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    read_only: true
    tmpfs:
      - /var/cache/nginx:noexec,nosuid,size=64m
      - /var/run:noexec,nosuid,size=32m

  vpn-api:
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    environment:
      - NODE_ENV=production
      - LOG_LEVEL=warn
      - API_RATE_LIMIT=100
      - API_TIMEOUT=30000
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=64m

  postgres:
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    environment:
      - POSTGRES_MAX_CONNECTIONS=100
      - POSTGRES_SHARED_BUFFERS=256MB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=1GB
      - POSTGRES_WORK_MEM=4MB
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./backups:/backups:ro
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: >
      postgres
      -c max_connections=100
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c work_mem=4MB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100

  redis:
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    command: >
      redis-server
      --appendonly yes
      --requirepass ${REDIS_PASSWORD:-changepassword}
      --maxmemory 200mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  prometheus:
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  grafana:
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    environment:
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_SECURITY_DISABLE_GRAVATAR=true
      - GF_ANALYTICS_REPORTING_ENABLED=false
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  jaeger:
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    environment:
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=${ELASTICSEARCH_URL:-http://elasticsearch:9200}
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Production-only services
  backup:
    image: postgres:15-alpine
    container_name: vpn-backup
    restart: "no"
    environment:
      - PGPASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - ./backups:/backups
      - ./scripts/backup.sh:/backup.sh:ro
    networks:
      - vpn-internal
    command: ["/backup.sh"]
    depends_on:
      - postgres
    profiles:
      - backup

  log-aggregator:
    image: fluent/fluent-bit:latest
    container_name: vpn-log-aggregator
    restart: unless-stopped
    volumes:
      - ./configs/fluent-bit:/fluent-bit/etc:ro
      - vpn-logs:/var/log/vpn:ro
    networks:
      - vpn-internal
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    profiles:
      - logging

# Production-specific volumes
volumes:
  backup-storage:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/vpn/backups